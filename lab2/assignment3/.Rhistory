mse_train_vector <<- c(mse_train_vector, mse_train)
mse_test_vector <<- c(mse_test_vector, mse_test)
return(mse_train_Vector)
}
theta = rep(0, 100)
opt = optim(par = theta, fn = cost, method = "BFGS")
x_train = as.matrix(train %>% select(-ViolentCrimesPerPop))
x_test = as.matrix(test %>% select(-ViolentCrimesPerPop))
y_train = train$ViolentCrimesPerPop
y_test = test$ViolentCrimesPerPop
#multi_mse_test = c()
#multi_mse_train = c()
mse_test_vector = c()
mse_train_vector = c()
cost <- function(theta) {
mse_train = mean((y_train - x_train %*% theta)^2)
mse_test = mean((y_test - x_test %*% theta)^2)
mse_train_vector <<- c(mse_train_vector, mse_train)
mse_test_vector <<- c(mse_test_vector, mse_test)
return(mse_train_vector)
}
theta = rep(0, 100)
opt = optim(par = theta, fn = cost, method = "BFGS")
plot(mse_train_vector[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "green")
points(mse_test_vector[500:8000], col = "blue", pch = ".")
opt_iteration <- which.min(mse_test_vector)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("blue", "green"), lwd = 1)
# training and test error in the optimal model
mse_train_vector[opt_iteration] # 0.3032999
mse_test_vector[opt_iteration] # 0.4002329
##### Task 1 #####
#################
#Read data from file
data = read.csv("communities.csv")
#extract the target variable column and the 16 column containing the prediction parameters
library(dplyr) #library to use select function
#prediction_parameter_data = dataframe  %>% select(1:100)
#Scale the data
library(caret) #library for scaling
scaler = preProcess( data %>% select(-ViolentCrimesPerPop)) #preProcess() to learn transformation
data = predict(scaler, data) #predict() to apply transformation
#Calculate the covariance matrix
cov = cov(data)
#calculate all eigenvalues and eigenvectors
eig = eigen(cov)
#cumulative add all eigenvalues, meaning that the tenth value is the sum of all values in position 1-10.
cs = cumsum(eig$values / sum(eig$values) * 100)
#display the first position with a value of 95 or higher
which(cs >=95)[1] #35 components required
cs[1]
scaler = preProcess( data %>% select(-ViolentCrimesPerPop)) #preProcess() to learn transformation
data = predict(scaler, data) #predict() to apply transformation
#Calculate the covariance matrix
cov = cov(data)
#calculate all eigenvalues and eigenvectors
eig = eigen(cov)
#cumulative add all eigenvalues, meaning that the tenth value is the sum of all values in position 1-10.
cs = cumsum(eig$values / sum(eig$values) * 100)
cs[1]
cs[2]
eig[1]
eig[2]
eig$values[1]
eig$values[1]
eig$values[2]
scaler = preProcess( data %>% select(-ViolentCrimesPerPop)) #preProcess() to learn transformation
data = predict(scaler, data) #predict() to apply transformation
#Calculate the covariance matrix
cov = cov(data)
#calculate all eigenvalues and eigenvectors
eig = eigen(cov)
#cumulative add all eigenvalues, meaning that the tenth value is the sum of all values in position 1-10.
cs = cumsum(eig$values / sum(eig$values) * 100)
eig$values[1]
eig$values[2]
#display the first position with a value of 95 or higher
which(cs >=95)[1] #35 components required
#The variation described by the two first principal components
cs[1]
cs[2] #41.95576
sum(eig$values[1:2]) # 41.9785
principal_comp = princomp(data)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 5)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 5)
library(ggfortify)
library(ggplot2)
autoplot(principal_comp, colour = "ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color = "Violent crimes per pop.")
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
top_5
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 5)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "green", pch = 5)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "purple", pch = 5)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "yellow", pch = 5)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 5, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 5)
data2 = data %>% select (medFamInc)
View(data2)
data2 = data %>% select (medFamInc)
data = read.csv("communities.csv")
data2 = data %>% select (medFamInc)
View(data2)
data2 = data %>% select (medFamInc, medIncome)
data2 = data %>% select (ViolentCrimesPerPop, medFamInc, medIncome, PctKids2Par, pctWInvInc, PctPopUnderPov)
library(ggfortify)
library(ggplot2)
autoplot(principal_comp, colour = "ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color = "Violent crimes per pop.")
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 5)
plot(principal_comp[["loadings"]][, 1], col = "blue", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "black", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
plot(principal_comp[["loadings"]][, 1], col = "green", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "darkgreen", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
plot(principal_comp[["loadings"]][, 1], col = "darkgreen", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "darkred", pch = 16)
#Perform PCA using function princomp()
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "darkgreen", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
plot(principal_comp[["loadings"]][, 1], col = "darkgreen", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "darkgreen", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
#Read data from file
data = read.csv("communities.csv")
#extract the target variable column and the 16 column containing the prediction parameters
library(dplyr) #library to use select function
#prediction_parameter_data = dataframe  %>% select(1:100)
#Scale the data
library(caret) #library for scaling
scaler = preProcess( data %>% select(-ViolentCrimesPerPop)) #preProcess() to learn transformation
data = predict(scaler, data) #predict() to apply transformation
#Calculate the covariance matrix
cov = cov(data)
#calculate all eigenvalues and eigenvectors
eig = eigen(cov)
#cumulative add all eigenvalues, meaning that the tenth value is the sum of all values in position 1-10.
cs = cumsum(eig$values / sum(eig$values) * 100)
eig$values[1]
eig$values[2]
#display the first position with a value of 95 or higher
which(cs >=95)[1] #35 components required
#The variation described by the two first principal components
cs[1]
cs[2] #41.95576
sum(eig$values[1:2]) # 41.9785
##### Task 2 #####
#################
#Perform PCA using function princomp()
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "black", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
x_train = as.matrix(train %>% select(-ViolentCrimesPerPop))
##### Task 1 #####
#################
#Read data from file
data = read.csv("communities.csv")
#extract the target variable column and the 16 column containing the prediction parameters
library(dplyr) #library to use select function
#prediction_parameter_data = dataframe  %>% select(1:100)
#Scale the data
library(caret) #library for scaling
scaler = preProcess( data %>% select(-ViolentCrimesPerPop)) #preProcess() to learn transformation
data = predict(scaler, data) #predict() to apply transformation
#Calculate the covariance matrix
cov = cov(data)
#calculate all eigenvalues and eigenvectors
eig = eigen(cov)
#cumulative add all eigenvalues, meaning that the tenth value is the sum of all values in position 1-10.
cs = cumsum(eig$values / sum(eig$values) * 100)
eig$values[1]
eig$values[2]
#display the first position with a value of 95 or higher
which(cs >=95)[1] #35 components required
#The variation described by the two first principal components
cs[1]
cs[2] #41.95576
sum(eig$values[1:2]) # 41.9785
##### Task 2 #####
#################
#Perform PCA using function princomp()
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "black", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
library(ggfortify)
library(ggplot2)
autoplot(principal_comp, colour = "ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color = "Violent crimes per pop.")
##### Task 3 #####
#################
n <- dim(data)[1]
set.seed(12345)
id <- sample(1:n, floor(n * 0.5))
train <- data[id, ]
test <- data[-id, ]
library(caret) #library for scaling
scaler = preProcess(train) #preProcess() to learn transformation
train = predict(scaler, train) #predict() to apply transformation
test = predict(scaler, test)
#Create a linear model with ViolerntCrimesPerPop as target variable
model = lm(ViolentCrimesPerPop~., data=train)
summary(model) #displays the model coefficients
#Predict based on the scaled test and training data using the linear model
predict_train = predict(model, train)
predict_test = predict(model, test)
#Calculate mean square error of actual motor_UPDRS vs predicted by model
MSE_on_predict_scaled_training_data = mean((train$ViolentCrimesPerPop - predict_train)^2)
MSE_on_predict_scaled_test_data = mean((test$ViolentCrimesPerPop - predict_test)^2)
##### Task 4 #####
#################
x_train = as.matrix(train %>% select(-ViolentCrimesPerPop))
x_test = as.matrix(test %>% select(-ViolentCrimesPerPop))
y_train = train$ViolentCrimesPerPop
y_test = test$ViolentCrimesPerPop
multi_mse_test = c()
multi_mse_train = c()
cost <- function(theta) {
mse_train = mean((y_train - x_train %*% theta)^2)
mse_test = mean((y_test - x_test %*% theta)^2)
multi_mse_train <<- c(multi_mse_train, mse_train)
multi_mse_test <<- c(multi_mse_test, mse_test)
return(mse_train)
}
theta = rep(0, 100)
opt = optim(par = theta, fn = cost, method = "BFGS")
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "green")
points(multi_mse_test[500:8000], col = "blue", pch = ".")
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("blue", "green"), lwd = 1)
# training and test error in the optimal model
multi_mse_train[opt_iteration] # 0.3032999
multi_mse_test[opt_iteration] # 0.4002329
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "blue", pch = ".")
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("blue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = ".")
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = 2)
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = 1)
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.8), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("test data", "training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.2, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 8000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
plot(multi_mse_train[500:7000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:7000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 8000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:7000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:7000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
plot(multi_mse_train[500:8000],
ylim = c(0.25, 0.75), ylab = "MSE",
xlab = "# of iterations",
pch = ".", xlim = c(500, 7000), col = "darkgreen")
points(multi_mse_test[500:8000], col = "darkblue", pch = '.')
opt_iteration <- which.min(multi_mse_test)
#abline(v = opt_iteration - 500, col = "grey", lty = "dashed")
legend("topright", c("Test data", "Training data"), col = c("darkblue", "darkgreen"), lwd = 1)
opt_iteration #the optimal iteration
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "black", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
library(ggfortify)
library(ggplot2)
autoplot(principal_comp, colour = "ViolentCrimesPerPop") +
labs(x = "PC1", y = "PC2", color = "Violent crimes per pop.")
n <- dim(data)[1]
set.seed(12345)
id <- sample(1:n, floor(n * 0.5))
train <- data[id, ]
test <- data[-id, ]
library(caret) #library for scaling
scaler = preProcess(train) #preProcess() to learn transformation
train = predict(scaler, train) #predict() to apply transformation
test = predict(scaler, test)
#Create a linear model with ViolerntCrimesPerPop as target variable
model = lm(ViolentCrimesPerPop~., data=train)
summary(model) #displays the model coefficients
#Predict based on the scaled test and training data using the linear model
predict_train = predict(model, train)
predict_test = predict(model, test)
#Calculate mean square error of actual motor_UPDRS vs predicted by model
MSE_on_predict_scaled_training_data = mean((train$ViolentCrimesPerPop - predict_train)^2)
MSE_on_predict_scaled_test_data = mean((test$ViolentCrimesPerPop - predict_test)^2)
principal_comp = princomp(data)
#trace plot of the first principal component (PC1)
plot(principal_comp[["loadings"]][, 1], col = "black", pch = 16, ylab = "")
#fetch the top 5 contributing features and how much they contribute with
top_5 = head(sort(abs(principal_comp[["loadings"]][, 1]), decreasing = TRUE), n = 5) #medFamInc, medIncome, pctWInvInce, PctPopUnderPov
top_5
#get the index of the top 5 contributing features
index_top_5 = which(abs(principal_comp[["loadings"]][, 1]) %in% top_5)
points(index_top_5, principal_comp[["loadings"]][index_top_5, 1], col = "red", pch = 16)
