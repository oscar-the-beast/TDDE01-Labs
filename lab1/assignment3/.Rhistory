#creating training data
train = diabetes%>%select(`Plasma glucose concentration`, `Age`,`Diabetes`)
m1 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m1)
#calculating prnbability of diabetes for each case with the probalistic model m1
Prob = predict(m1, type="response")
#Making predicitions from by using r=0.5
Pred_r50=ifelse(Prob>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.5):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r50 <- Pred_r50
#Making a plot with all the predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r50== 1, 'red', 'blue'))
#ans: the logistic regression model m1 uses two parameters to estimate if a person have diabetes or not, it has a 26,3% missclassification error which means that roughly 1 out of 4 persons will be missclassified
# It could therefore be seen as a bad model which is probably underfitted to the training data
#3.3
#extracting coefficients from m1
coefficients <- coef(m1)
#coefficients are
# coefficients[1] = -5.9134 (intercepts)
# coefficients[2] = 0.0356 (Plasma glucose)
# coefficients[3] = 0.0248 (age)
# decission boundry equation: 0 = -5.9124 + 0.0356 * x1 + 0.0248 * x2 //x1 = plasmaglucose, x2 = age// -->
# x1 = -5.9124/(-0.0356) + (0.0248/(-0.0356)) * x2
# calculate the slope and intercept of the decision boundary line
slope = coefficients[3]/(-coefficients[2])
intercept = (coefficients[1])/(-coefficients[2])
abline(intercept, slope,
lwd = 2, # line thickness
lty = 1) # type dashed
#3.4
#Making predicitions from by using r=0.2
Pred_r20=ifelse(Prob>0.2, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r20)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.2):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r20 <- Pred_r20
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r= 0.2)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r20 == 1, 'red', 'blue'))
#Making predicitions from by using r=0.8
Pred_r80=ifelse(Prob>0.8, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r80)
#printing the missclassification error in the console
print(paste("Misclassification Error (r = 0.8):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r80 <- Pred_r80
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.8)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r80 == 1, 'red', 'blue'))
#3.5
#Y = w0 + w1*x1+ w2*x2 + w3* z1
#z1 = x1^4
train$z1 = train$`Plasma glucose concentration`^4
#z2 = x1^3*x2
train$z2 = train$`Plasma glucose concentration`^3 * train$Age
#Z3 = x1^2*x2^2
train$z3 = train$`Plasma glucose concentration`^2 * train$Age^2
#Z4 = x1^*x2^3
train$z4 = train$`Plasma glucose concentration` * train$Age^3
#z5 = x2^4
train$z5 = train$Age^4
m2 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m2)
Prob_m2 = predict(m2, type="response")
Pred_m2_r50=ifelse(Prob_m2>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_m2_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (M2, r=0.5):", misclassification_error))
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes m2 model (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_m2_r50== 1, 'red', 'blue'))
View(diabetes)
setwd("~/TDDE01/TDDE01-Labs/lab1/assignment2")
dataframe = read.csv("parkinsons.csv")
##### Task 1 #####
#################
library(dplyr) #library for filtering
library(caret)
##divide data, 60% trainging data and 40% test data
#trainingData = dataframe %>% filter(subject. <=25) %>% select(5:5, 7:22)
#testData = dataframe %>% filter(subject.>25) %>% select(5:5, 7:22)
n <- dim(dataframe)[1]
set.seed(12345)
id <- sample(1:n, floor(n * 0.6))
trainingData <- dataframe[id, ]
testData <- dataframe[-id, ]
trainingData = trainingData  %>% select(5:5, 7:22)
testData = testData %>% select(5:5, 7:22)
library(caret) #library for scaling
scaler = preProcess(trainingData) #preProcess() to learn transformation
scaledTrainingData = predict(scaler, trainingData) #predict() to apply transformation
scaledTestData = predict(scaler, testData)
##### Task 2 #####
#################
trainingModel = lm(motor_UPDRS~., data=scaledTrainingData)
summary(trainingModel) #Jitter.RAP, Jitter.DDP, Shimmer.DDA & Shimmer.APQ3 are signifcant contributors to the model
predict_on_scaled_training_data = predict(trainingModel, scaledTrainingData)
predict_on_scaled_test_data = predict(trainingModel, scaledTestData)
MSE_on_predict_scaled_training_data = mean((scaledTrainingData$motor_UPDRS - predict_on_scaled_training_data)^2)
MSE_on_predict_scaled_test_data = mean((scaledTestData$motor_UPDRS - predict_on_scaled_test_data)^2)
MSE_on_predict_scaled_training_data
MSE_on_predict_scaled_test_data
##### Task 3 #####
#################
X = as.matrix(scaledTrainingData %>% select(Jitter...:PPE))
Y = as.matrix(scaledTrainingData$motor_UPDRS)
n = nrow(scaledTrainingData)
#-n/2*log(2*pi) is a constant
#-n/2*log(sigma^2) # penalizes models with larger variance
#- (1 / (2 * sigma^2)) * sum((y - x %*% theta)^2) sum of squared residuals, penalizing models that do not fit the data
#theta is the vector of model parameters
# sigma^2 is the variance of errors
Loglikelihood = function(theta, sigma) {
return(-n / 2 * log(2 * pi*sigma^2) - (1 / (2 * sigma^2)) * sum((Y - X %*% theta)^2))
}
#Add a ridge penalty to the negative loglikelihood function, where lambda is the ridge penalty
#Ridge penalty penalizes the model by adding the sum of squared values of the coefficients multiplied by lambda
#This helps to shrink the parameter estimates towards zero, providing regularization
Ridge = function(theta, lambda) {
sigma <- tail(theta, n = 1)
theta <- theta[-17]
return(lambda * sum(theta^2) - Loglikelihood(theta, sigma))
}
#computes optimal theta and sigma for the given lambda
RidgeOpt = function(lambda) {
return(optim(rep(1, 17), fn = Ridge, lambda = lambda, method = "BFGS"))
}
I = as.matrix(diag(16))
#Given the ridge penalty (based on lambda) how many parameters affect the model, i.e if we get 13 than we have effectivley shrinked 3 parameters
DF = function(lambda) {
return(sum(diag((X %*% solve((t(X) %*% X + lambda * I))) %*% t(X))))
}
##### Task 4 #####
#################
opt_theta1 = RidgeOpt(lambda=1)
opt_theta100 = RidgeOpt(lambda=100)
opt_theta1000 = RidgeOpt(lambda=1000)
x_trainingData = as.matrix(scaledTrainingData %>% select(Jitter...:PPE))
x_testData = as.matrix(scaledTestData %>% select(Jitter...:PPE))
opt1 = as.matrix(opt_theta1$par[-17])
opt100 = as.matrix(opt_theta100$par[-17])
opt1000 = as.matrix(opt_theta1000$par[-17])
#Perform predictions of motor_UPDRS values
predict_training_opt1 = x_trainingData %*% opt1
predict_training_opt100 = x_trainingData %*% opt100
predict_training_opt1000 = x_trainingData %*% opt1000
predict_test_opt1 = x_testData %*% opt1
predict_test_opt100 = x_testData %*% opt100
predict_test_opt1000 = x_testData %*% opt1000
#Calculate mean square error
mse_training_opt1 = mean((scaledTrainingData$motor_UPDRS - predict_training_opt1)^2)
mse_training_opt100 = mean((scaledTrainingData$motor_UPDRS - predict_training_opt100)^2)
mse_training_opt1000 = mean((scaledTrainingData$motor_UPDRS - predict_training_opt1000)^2)
mse_test_opt1 = mean((scaledTestData$motor_UPDRS - predict_test_opt1)^2)
mse_test_opt100 = mean((scaledTestData$motor_UPDRS - predict_test_opt100)^2)
mse_test_opt1000 = mean((scaledTestData$motor_UPDRS - predict_test_opt1000)^2)
#Calculate degrees of freedom
df1 = DF(lambda=1) #13.85375
df2 = DF(lambda = 100) #9.72796
df3 = DF(lambda=1000) #5.437577
df3
setwd("~/TDDE01/TDDE01-Labs/lab1/assignment1")
# """""""""""""""""""""""""""""" Assignment 1 """""""""""""""""""""""""""""" #
library(kknn)
#Read data from file
data <- read.csv("optdigits.csv", header=FALSE)
#Create training set (50% of data)
n <- dim(data)[1]
set.seed(12345)
id <- sample(1:n, floor(n * 0.5))
train <- data[id,]
#Create validation set (25% of data)
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.25))
valid <- data[id2,]
#Create test set (25 of data)
id3 <- setdiff(id1, id2)
test <- data[id3,]
# """""""""""""""""""""""""""""" Assignment 2 """""""""""""""""""""""""""""" #
#Set formula for the models, which is the last column of the training set
formula_string <- as.formula(paste("as.factor(", colnames(train)[ncol(train)], ") ~ ."))
#Create model for train and test (model for test is model and model for train is model1)
model <- kknn(formula_string, train, test, kernel="rectangular", k = 30)
model1 <- kknn(formula_string, train, train, kernel="rectangular", k = 30)
#Predict train and test based on their model
train_predictions <- as.numeric(predict(model1, newdata = train))
test_predictions <- as.numeric(predict(model, newdata = test))
#Find target number for train and test, which is in their last column
trainingTarget <- as.numeric(train$V65)
testTarget <- as.numeric(test$V65)
#Create confusion matrix for train and test based on their target and predictions
confusion_matrix_train <- table(trainingTarget, train_predictions)
confusion_matrix_test <- table(testTarget, test_predictions)
print(confusion_matrix_test)
print(confusion_matrix_train)
#Calculate misclassification for train and test
misclassification_error_train = 1 - sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)
misclassification_error_test = 1 - sum(diag(confusion_matrix_test)) / sum(confusion_matrix_test)
# """""""""""""""""""""""""""""" Assignment 3 """""""""""""""""""""""""""""" #
#Find all indices of target 8 on the training set
search_num = 8
indices_8 <- which(train[, ncol(train)] == search_num)
#Get all probabilities of a number being an eight aswell as getting those probabilities where the answer should be 8
probabilities <- model1$prob[, as.character(search_num)]
probabilities_8 <- probabilities[indices_8]
# Find the indices of the easiest and hardest cases in the original dataset
easiest_cases <- indices_8[order(probabilities_8, decreasing = TRUE)[1:2]]
hardest_cases <- indices_8[order(probabilities_8, decreasing = FALSE)[1:3]]
# Extract features for the easiest and hardest cases
easiest_features <- train[easiest_cases, -ncol(train)]
hardest_features <- train[hardest_cases, -ncol(train)]
reshape_as_matrix <- function(features) {
matrix(as.numeric(features), nrow = 8, byrow = TRUE)
}
#Matrix is upside down without having this function
reverse_rows <- function(mat) {
mat[nrow(mat):1, ]
}
#Create a heatmap for each case
for (i in 1:2) {
heatmap(reverse_rows(reshape_as_matrix(easiest_features[i, ])), Colv = NA, Rowv = NA,
main = paste("Easiest Case", i), xlab = "", ylab = "")
}
for (i in 1:3) {
heatmap(reverse_rows(reshape_as_matrix(hardest_features[i, ])), Colv = NA, Rowv = NA,
main = paste("Hardest Case", i), xlab = "", ylab = "")
}
# """""""""""""""""""""""""""""" Assignment 4 """""""""""""""""""""""""""""" #
vector_nums <- c(1:30)
misclassification_error_train_list <- numeric(length(vector_nums))
misclassification_error_validation_list <- numeric(length(vector_nums))
optimal_k = NULL
for (num in vector_nums) {
model <- kknn(formula_string, train, valid, kernel="rectangular", k = num)
model1 <- kknn(formula_string, train, train, kernel="rectangular", k = num)
train_predictions <- as.numeric(predict(model1, newdata = train))
validation_predictions <- as.numeric(predict(model, newdata = valid))
trainingTarget <- as.numeric(train$V65)
validationTarget <- as.numeric(valid$V65)
confusion_matrix_train <- table(trainingTarget, train_predictions)
confusion_matrix_validation <- table(validationTarget, validation_predictions)
misclassification_error_validation <- 1 - sum(diag(confusion_matrix_validation)) / sum(confusion_matrix_validation)
misclassification_error_train_list[num] = 1 - sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)
misclassification_error_validation_list[num] = misclassification_error_validation
if (is.null(optimal_k) || misclassification_error_validation < misclassification_error_validation_list[optimal_k])
optimal_k <- num
}
print(optimal_k)
plot(vector_nums, misclassification_error_train_list, ylab = "misclassification error", xlab = "k", col="green")
points(vector_nums, misclassification_error_validation_list, col="red")
model <- kknn(formula_string, train, valid, kernel="rectangular", k = optimal_k)
model1 <- kknn(formula_string, train, train, kernel="rectangular", k = optimal_k)
model2 <- kknn(formula_string, train, test, kernel="rectangular", k = optimal_k)
train_predictions <- as.numeric(predict(model1, newdata = train))
test_predictions <- as.numeric(predict(model2, newdata = test))
validation_predictions <- as.numeric(predict(model, newdata = valid))
trainingTarget <- as.numeric(train$V65)
testTarget <- as.numeric(test$V65)
validationTarget <- as.numeric(valid$V65)
confusion_matrix_train <- table(trainingTarget, train_predictions)
confusion_matrix_test <- table(testTarget, test_predictions)
confusion_matrix_validation <- table(validationTarget, validation_predictions)
misclassification_error_train = 1 - sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)
misclassification_error_test = 1 - sum(diag(confusion_matrix_test)) / sum(confusion_matrix_test)
misclassification_error_validation = 1 - sum(diag(confusion_matrix_validation)) / sum(confusion_matrix_validation)
print(misclassification_error_test)
print(misclassification_error_train)
print(misclassification_error_validation)
# """""""""""""""""""""""""""""" Assignment 5 """""""""""""""""""""""""""""" #
cross_entropy_errors <- vector("numeric", length = 30)
for (k in 1:30) {
model <- kknn(formula_string, train, valid, k = k)
# Extract probabilities for all instances in the validation set
probabilities <- model$prob
# Probability smoothing
eps <- 1e-15
probabilities[probabilities == 0] <- eps
# Assuming valid[, target_column] represents the true classes
true_number <- as.numeric(as.factor(valid$V65))
# Calculate cross-entropy
cross_entropy_errors[k] <- -sum(log(probabilities[cbind(1:nrow(valid), true_number)]))
}
# Plot the dependence of cross-entropy on K
plot(1:30, cross_entropy_errors, type = "l", col = "blue", xlab = "K", ylab = "Cross-Entropy", main = "Cross-Entropy vs. K")
# Find the optimal K based on the minimum cross-entropy
optimal_k <- which.min(cross_entropy_errors)
cat("Optimal K:", optimal_k, "\n")
library(dplyr)
setwd("~/TDDE01/TDDE01-Labs/lab1/assignment3")
diabetes = read.csv("pima-indians-diabetes.csv", header = FALSE)
colnames(diabetes) <- c("Number of times pregnant", "Plasma glucose concentration", "Diastolic blood pressure","Triceps skinfold thickness", "2-Hour serum insulin", "Body mass index", "Diabetes pedigree function", "Age", "Diabetes")
#3.1 make a scatterplott
plot(diabetes$`Age`, diabetes$`Plasma glucose concentration`, main = "Plasma glucose concentration vs asge (3.1)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(diabetes$`Diabetes`== 1, 'red', 'blue'))
# Ans: looking at the scatterplot for diabetes depending on plasma glucose, it seems like it will be hard to create a logic regression model for these two parameters
#3.2 train logistic regression model
#creating training data
train = diabetes%>%select(`Plasma glucose concentration`, `Age`,`Diabetes`)
m1 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m1)
#calculating prnbability of diabetes for each case with the probalistic model m1
Prob = predict(m1, type="response")
#Making predicitions from by using r=0.5
Pred_r50=ifelse(Prob>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.5):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r50 <- Pred_r50
#Making a plot with all the predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r50== 1, 'red', 'blue'))
#ans: the logistic regression model m1 uses two parameters to estimate if a person have diabetes or not, it has a 26,3% missclassification error which means that roughly 1 out of 4 persons will be missclassified
# It could therefore be seen as a bad model which is probably underfitted to the training data
#3.3
#extracting coefficients from m1
coefficients <- coef(m1)
#coefficients are
# coefficients[1] = -5.9134 (intercepts)
# coefficients[2] = 0.0356 (Plasma glucose)
# coefficients[3] = 0.0248 (age)
# decission boundry equation: 0 = -5.9124 + 0.0356 * x1 + 0.0248 * x2 //x1 = plasmaglucose, x2 = age// -->
# x1 = -5.9124/(-0.0356) + (0.0248/(-0.0356)) * x2
# calculate the slope and intercept of the decision boundary line
slope = coefficients[3]/(-coefficients[2])
intercept = (coefficients[1])/(-coefficients[2])
abline(intercept, slope,
lwd = 2, # line thickness
lty = 1) # type dashed
#3.4
#Making predicitions from by using r=0.2
Pred_r20=ifelse(Prob>0.2, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r20)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.2):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r20 <- Pred_r20
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r= 0.2)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r20 == 1, 'red', 'blue'))
#Making predicitions from by using r=0.8
Pred_r80=ifelse(Prob>0.8, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r80)
#printing the missclassification error in the console
print(paste("Misclassification Error (r = 0.8):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r80 <- Pred_r80
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.8)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r80 == 1, 'red', 'blue'))
#3.5
#Y = w0 + w1*x1+ w2*x2 + w3* z1
#z1 = x1^4
train$z1 = train$`Plasma glucose concentration`^4
#z2 = x1^3*x2
train$z2 = train$`Plasma glucose concentration`^3 * train$Age
#Z3 = x1^2*x2^2
train$z3 = train$`Plasma glucose concentration`^2 * train$Age^2
#Z4 = x1^*x2^3
train$z4 = train$`Plasma glucose concentration` * train$Age^3
#z5 = x2^4
train$z5 = train$Age^4
m2 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m2)
Prob_m2 = predict(m2, type="response")
Pred_m2_r50=ifelse(Prob_m2>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_m2_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (M2, r=0.5):", misclassification_error))
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes m2 model (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_m2_r50== 1, 'red', 'blue'))
#creating training data
train = diabetes%>%select(`Plasma glucose concentration`, `Age`,`Diabetes`)
m1 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m1)
#calculating prnbability of diabetes for each case with the probalistic model m1
Prob = predict(m1, type="response")
#Making predicitions from by using r=0.5
Pred_r50=ifelse(Prob>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.5):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r50 <- Pred_r50
#Making a plot with all the predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r50== 1, 'red', 'blue'))
View(m1)
library(dplyr)
setwd("~/TDDE01/TDDE01-Labs/lab1/assignment3")
diabetes = read.csv("pima-indians-diabetes.csv", header = FALSE)
colnames(diabetes) <- c("Number of times pregnant", "Plasma glucose concentration", "Diastolic blood pressure","Triceps skinfold thickness", "2-Hour serum insulin", "Body mass index", "Diabetes pedigree function", "Age", "Diabetes")
#3.1 make a scatterplott
plot(diabetes$`Age`, diabetes$`Plasma glucose concentration`, main = "Plasma glucose concentration vs asge (3.1)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(diabetes$`Diabetes`== 1, 'red', 'blue'))
# Ans: looking at the scatterplot for diabetes depending on plasma glucose, it seems like it will be hard to create a logic regression model for these two parameters
#3.2 train logistic regression model
#creating training data
train = diabetes%>%select(`Plasma glucose concentration`, `Age`,`Diabetes`)
m1 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m1)
#calculating prnbability of diabetes for each case with the probalistic model m1
Prob = predict(m1, type="response")
#Making predicitions from by using r=0.5
Pred_r50=ifelse(Prob>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.5):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r50 <- Pred_r50
#Making a plot with all the predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r50== 1, 'red', 'blue'))
#ans: the logistic regression model m1 uses two parameters to estimate if a person have diabetes or not, it has a 26,3% missclassification error which means that roughly 1 out of 4 persons will be missclassified
# It could therefore be seen as a bad model which is probably underfitted to the training data
#3.3
#extracting coefficients from m1
coefficients <- coef(m1)
#coefficients are
# coefficients[1] = -5.9134 (intercepts)
# coefficients[2] = 0.0356 (Plasma glucose)
# coefficients[3] = 0.0248 (age)
# decission boundry equation: 0 = -5.9124 + 0.0356 * x1 + 0.0248 * x2 //x1 = plasmaglucose, x2 = age// -->
# x1 = -5.9124/(-0.0356) + (0.0248/(-0.0356)) * x2
# calculate the slope and intercept of the decision boundary line
slope = coefficients[3]/(-coefficients[2])
intercept = (coefficients[1])/(-coefficients[2])
abline(intercept, slope,
lwd = 2, # line thickness
lty = 1) # type dashed
#3.4
#Making predicitions from by using r=0.2
Pred_r20=ifelse(Prob>0.2, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r20)
#printing the missclassification error in the console
print(paste("Misclassification Error (r=0.2):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r20 <- Pred_r20
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r= 0.2)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r20 == 1, 'red', 'blue'))
#Making predicitions from by using r=0.8
Pred_r80=ifelse(Prob>0.8, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_r80)
#printing the missclassification error in the console
print(paste("Misclassification Error (r = 0.8):", misclassification_error))
#adding a column named predictions with all the predicitons made by model m1
#train$Prediction_r80 <- Pred_r80
#Making a plot with all trhe predicted values
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes (r = 0.8)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_r80 == 1, 'red', 'blue'))
#3.5
#Y = w0 + w1*x1+ w2*x2 + w3* z1
#z1 = x1^4
train$z1 = train$`Plasma glucose concentration`^4
#z2 = x1^3*x2
train$z2 = train$`Plasma glucose concentration`^3 * train$Age
#Z3 = x1^2*x2^2
train$z3 = train$`Plasma glucose concentration`^2 * train$Age^2
#Z4 = x1^*x2^3
train$z4 = train$`Plasma glucose concentration` * train$Age^3
#z5 = x2^4
train$z5 = train$Age^4
m2 = glm(Diabetes ~., train, family = 'binomial')
#creating summary of m1
summary(m2)
Prob_m2 = predict(m2, type="response")
Pred_m2_r50=ifelse(Prob_m2>0.5, "1", "0")
#calculating the missclassification error for m1
misclassification_error <- mean(train$Diabetes != Pred_m2_r50)
#printing the missclassification error in the console
print(paste("Misclassification Error (M2, r=0.5):", misclassification_error))
plot(train$`Age`, train$`Plasma glucose concentration`, main = "Predicted values for Diabetes m2 model (r = 0.5)",
xlab = "age", ylab = "Plasma glucose concentration",
pch = 16, col = ifelse(Pred_m2_r50== 1, 'red', 'blue'))
